---
title: AWS 2
author: lukey0515
date: 2023-07-18 22:10:00 +0800
categories: [Cloud, Amazon Cloud]
tags: [Cloud, AWS, Architecture]
render_with_liquid: false
---

# 지난 수업 요약

### Module 1

- AWS 서비스

  - 고객들이 AWS 서비스 사용하는 이유
    - 민첩성
      - 직접 서버 만드는데 걸리는 시간 줄여줄 수 있음
      - 오토 스케일링도 가능
    - 복잡성 및 위험 감소
      - 보안 취약성 최소화
      - 초기 비용 적음 -> 스타트업에 좋음
      - 자동화 시스템을 통해 휴먼 리소스 적게 필요 -> 관리 복잡성 감소
  - AWS 사용 방법 3가지 : 각각의 사용 방법은 다르지만 내부적으로는 같은 API 호출이 이루어짐
    - 관리 콘솔
    - CLI - 터미널로 사용하는 방법
    - SDK - 프로그래밍 방식으로 AWS 사용하는 방법
    - management console보다 CLI나 SDK가 더 할 수 있는 게 많음
  - 비관리형 / 관리형 / 서버리스 서비스
    - 비관리형 - ec2 인스턴스(서버만 빌려주기 때문에)처럼 관리가 필요 없는 서비스
    - 관리형 - rds처럼 백업/복구 시간만 정해주면 알아서 자동으로 해줌
    - 서버리스 = 완전 관리형 서비스
    - 클라우드 전문용어로는 Iaas, Saas, Paas 라고 부름
    - 인프라만 넣는 것, 플랫폼 as service, software as service - 예전에는 차별화를 위해 각 회사들이 선택한 전략이었는데 요즘은 모든 회사들이 다 지원하기 때문에 의미가 크게 없어졌다.

- AWS 인프라
  - 데이터 센터
  - 가용 영역
  - 리전
  - 로컬존
  - 엣지 로케이션
  - 데이터 센터가 모여 가용 영역, 가용 영역이 모여 리전
  - 모든 곳에 데이터 센터가 있을 수 없어서 만드는 작은 데이터 센터가 로컬 존
  - 가용 영역과 리전은 꼭 기억해야 함
  - 엣지 로케이션은 캐싱 기능을 도우는 영역
- Well-Architected Framework
  - 보안
  - 비용 최적화
  - 안정성
  - 성능효율성
  - 운영 우수성
  - 지속 가능성

## Module2 - IAM

- IAM(Identity and Access Management): AWS사용을 위한 사용자의 인가 및 권한의 인가 작업을 해주는 서비스
  - 사용자(User): 영속된 자격증명(한번 만들면 지우거나 바꾸지 않는한 계속 사용 할수 있음, 주의: 계정(account)는 Root를 얘기 하는 것임, IAM 사용자는 IAM서비스에서 만든 사용자를 칭함.)
  - 그룹(Group): 특정 용도의 사용자들의 집합
  - 역할(Role): 임시 자격증명(만료 시간이 있어서 일정시간만 사용할수 있음)
    - AWS 리소스에 AWS 서비스에 대한 액세스를 제공합니다.
    - 외부 인증 사용자(facebook, amazon, google)에게 액세스를 제공합니다.
    - 타사의 인증서버를 통한 SSO 액세스를 제공합니다.
    - 다른 계정으로 교차 계정 액세스 지원
    - 보안 상 여러 사용자를 관리하는 것은 리스크가 크기 때문에 임시 자격 증명을 만들어서 SSO -> 보안이 강력해
  - 정책(Policy): 권한들의 집합. JSON 문법으로 정의
    - 자격증명 기반 권한/정책: IAM 사용자에 연결되어 있으며 사용자가 할 수 있도록 허용된 작업
    - 리소스 기반 권한/정책: 리소스에 연결되며 지정된 사용자(또는 사용자 그룹)가 해당 리소스를 사용하여 수행할 수 있는 작업
    - 물론 IAM에서 모든 정책을 정해줄 수 있지만, 분명 불편해지는 상황이 생기기 때문에 리소스 입장에서 권한을 주는 방식이 필요할 수 있다. - 충돌이 일어날 수 있지만, 정책의 판단기준에 따라 적용된다(deny 우선적용)
    - 실제로는 SCP라고 세션 정책도 존재 - 너무 딥해서 다루진 않음
  - 페더레이션: Role with SAML, SSO
  - 다중계정 관리
    - Organizations - 하나의 루트를 사용하는 것이 아니라 팀마다 루트를 가지는 방식 - 필요한 시점은 재정을 담당하는 팀과 관련이 되었을 때 -> 여러 루트를 사용하게 되면 루트 제한이 필요해지므로 Organizations를 사용(신의 권한을 없애는 작업이 가능해짐)
      - SCP 사용
    - Control Tower 솔루션

## Module3 - 네트워킹 1

- CIDR 주소 체계
  - 10.0.0.2/16(prefix) 앞에서부터 고정
- VPC
  - 서브넷
    - 퍼블릭, 프라이빗 서브넷 -> 무조건 2개 이상씩은 만들어서 2개 이상의 가용영역을 만들어야 고가용성이라는 의미가 있음
  - 라우팅 테이블
  - NAT(나트 게이트웨이)
    - 프라이빗 서브넷에서도 인터넷을 하기 위해 사용
    - IP 공유기도 이 역할 - 외부에서의 접근은 차단하고 내부에서 외부로 나가는 것은 허용하는 것
  - IGW(인터넷 게이트웨이)
    - VPC는 무조건 인터넷 게이트웨이가 있어야 인터넷이 가능하다.
    - 인터넷이 되려는 조건 - 인터넷 게이트웨이(통로 역할), 퍼블릭 서브넷에 퍼블릭 IP 할당(공인 IP 할당), 라우트 테이블(외부에서 들어오는 트래픽과 내부에서 도는 트래픽을 구분하여 어디로 가야할지 트래픽을 조정해줌)
  - NACL(Network Access Control List)
  - 보안 그룹
    - 방화벽을 의미
    - VPC는 무조건 security group 필수, 아무나 들어와서 접근하는 것을 막기 위함, PC에서 65000개의 포트를 사용할 수 있고 그중 1000개 정도는 이미 예약이 되어 있음
    - 화이트리스 정책 - 블랙리스트 정책은 블락시킨 것들을 차단시키는 정책이라면 화이트리스 정책은 원하는 위치에만 열어두고 나머지는 막아두는 방법으로 보안 관련 정책에서 많이 사용하는 정책
    - 필요에 따라 블랙리스트 정책이 필요한 경우도 존재
    - 네트워크 들어오는 방법 : VPC -> VPC 의 서브넷 -> 서브넷 방화벽(NACL) - 보안을 엄격하게 한다면 필요, NACL이 블랙리스트 정책에 해당
    - 인터넷을 한다 = (모든 통신 장비에는) 랜 카드가 존재한다. (네트워크 인터페이스 카드 : NIC, AWS에는 ENI(Elastic Network Interface)라고 부름), 랜 카드를 통해 트래픽이 들어온다.
    - 보안 그룹은 인스턴스가 아닌 랜 카드에 붙는다.
    - 하나의 인스턴스에 여러 개의 랜 카드 붙일 수 있음 - 일반적인 보안 프로그램들은 들어오는 트래픽, 나가는 트래픽 -> 2개의 ENI를 붙인다 (ENI는 붙였다 뗄 수 있다.)
  - EIP
  - ENI
- EC2 만들기 위해서는 VPC를 먼저 만들어야 함
  - 만들지 않으면 default VPC를 사용하는 것 - public subnet밖에 존재하지 않음 -> 여기에 db 넣으면 털린다.

---

# VPC 실습

1. VPC 생성
   1. cidr 범위가 중요
2. VPC 내에 subnet 생성
   1. DNS - domain name server 2. domain : naver와 같은 영문 주소를 말함 3. 컴퓨터는 domain이 아닌 IP 주소를 알아들음 4. -> 도메인 서버에 IP 주소를 물어 받아서 접속이 가능해짐
   2. public subnet
      1. 공인 IP를 할당해주어야 인터넷이 가능해짐
   3. private subnet
      1. 대부분이 private subnet에 저장될 것이기 때문에 public subnet보다 더 넓게 사용함
   4. 인터넷 게이트웨이
      1. 만들고 VPC에 붙여주는 작업 필요
   5. 라우트 테이블
      1. 목적 : 트래픽이 어디로 나가야 하는지 알려주기 위함
      2. 기본적으로 destination(VPC IP 대역이 그대로 들어가 있음), target(로컬)이 정해짐
         1. VPC IP 대역을 나의 사설 네트워크(내부)에서 사용하라는 의미
         2. 기본적으로 설정된 이 route는 삭제도 안 됨
      3. 그 외의 route 추가
         1. 0.0.0.0/0 - 미리 예약된 IP로 모든 IP를 의미
         2. 라우트 테이블에 우선순위가 존재하여 (LPM : longest prefix match- 가장 긴 prefix(가장 작은 것을 의미) 먼저 매치하는 알고리즘에 따라) 내부에서 도는 IP 먼저 적용되기 때문에 내부 외의 IP는 밖으로 나가도록 만들어주는 것
      4. 어떤 서브넷을 사용할 것인지 지정해주어야 함 - subnet association
   6. security groups
      1. security group은 차단은 안 되지만 특정 위치에서만 오도록 설정할 수 있음
      2. 웹 서버에서만/앱 서버에서만 오게 설정 가능 - security chain
      3. optional한 태그를 설정한 이유? 리소스 개수가 많아지면 구분/관리하기 힘들어짐 -> 코딩 컨벤션처럼 팀 내에서 태그 컨벤션을 정해두는 것이 좋음
         1. 넷플릭스에서 공개한 오픈소스 중 어떤 건 태그를 지정 안 하면 자동으로 삭제되는 거도 있다.
   7. ec2 instance 생성 - 잘 연결/만들어졌는지 확인 위함
      1. AMI - 운영체제 결정 (아마존에서 이미 만들어둔 이미지들)
      2. 타입 - 사양의 결정
         1. c -> cpu 좋은 것
         2. g -> gpu 좋은 것
         3. xl -> 성능이 좋아지면서 비용도 비싸짐
   8. NAT gateway
      1. private subnet의 라우팅을 위함
      2. public subnet이 인터넷이 가능한 영역이므로, public subnet에 설치가 되어야 함
      3. IP 공유기와 마찬가지로 하나의 공인 IP를 공유함
      4. IP 공유기가 껐다 켜면 IP가 바뀌는 것과 달리 고정 IP를 사용
      5. private Route Table 만들고 subnet association 설정
   9. 보안 그룹
      1. 보통 public subnet이 웹 서버, private subnet이 앱 서버일 것
      2. 웹 서버에서 오도록 source 설정정

---

# 네트워크 복습

1. IP 주소
   1. 앞을 네트워크 식별, 뒤를
2. CIDR
   1. prefix가 가장 중요
   2. CIDR 최대 범위는 28까지 가능
   3. 특정 IP를 차단해야 할 때 prefix를 어떻게 두어야 할까 - IP/32를 사용
   4. 숫자가 커질수록 범위가 좁아짐
3. elastic network interface = lan 카드
4. VPC
   1. 서브넷
      1. 시작 IP 대역이 정해져 있음 10 / 172 / 196? 으로 정해져있음
   2. 퍼블릭 서브넷
      1. 라우팅 테이블, 인터넷 게이트웨이, 퍼블릭 IP 주소가 있어야 인터넷 가능
   3. 라우팅 테이블
      1. 어디로 가야하는 지 알려주는 역할
      2. 내부/외부로 가는 것을 알려줌
5. VPC 트래픽 보안
   1. NACL : 서브넷 영역 방화벽
      1. rule을 만들어 포트 범위의 허용/거부 여부를 결정
      2. 기본적으로는 모두 허용으로 설정되어 있음
      3. 거부 정책이 존재
   2. 보안 그룹
      1. 일반적으로 인스턴스에 붙임
      2. 랜카드가 붙는 모든 장비에 붙일 수 있음
      3. 모든 인바운드 트래픽 차단, 모든 아웃바운드 트래픽 허용
      4. NACL은 stateless-상태를 저장하지 않음 = 나가는 트래픽과 들어오는 트래픽 기억하지 못해서 들어온 트래픽이 있으면 나갈 때 다시 열어줘야 함
      5. 보안 그룹은 stateful - 들어온 포트를 기억하고 있다가 나갈 때 다시 열어줘야 할 필요가 없음
      6. 일반적으로 예전에 만든 장비들이 stateful하여 상태를 서버에 저장함 -> 클라우드에 넘어오면서 상태를 공유하기 힘들어짐 -> 클라우드로 넘어오면서 stateless하게 만드는 트렌드가 생김
      7. 앞에서 오는 트래픽만 받겠다 = 보안 그룹의 소스 설정으로 제어 -> security chain : 계층이 만들어져 보안이 강력해진다.
   3. 다중 방어
      1. 인터넷 게이트 웨이를 통해 사용자가 들어오고 인스턴스까지 전달된다.
         1. 라우팅 테이블이 인스턴스 위치를 알고 방향을 알려줌
         2. 방화벽 역할을 하는 네트워크 ACL이 허용된 포트인지 확인
         3. 퍼블릭 서브넷을 거쳐 LAN 카드를 마주쳐 보안그룹 확인
         4. 이후 인스턴스에 도착
      2. 보안이 철저 - AWS 잘 되는 이유
   4. 보안 그룹과 네트워크 ACL 비교가 잦음
      1. 허용 규칙만 / 허용 규칙 및 거부 규칙
      2. 상태 저장 / 비저장
      3. 모든 규칙 평가 / 순서대로 평가
         1. ACL - 숫자가 낮은 게 우선적으로 적용
      4. ENI 연결 / 서브넷 연결
      5. 인스턴스에만 적용 / 서브넷 전체 적용

---

### 지식 확인

- VPC 는 서브넷의 가용영역 여러 개는 사용할 수 있지만 리전을 넘어갈 수 없다.
- 서브넷을 퍼블릭으로 설정하려면 인터넷 게이트웨이 설정해야 함
  - 기본적으로 인바운드 트래픽이 설정되어있으므로 아웃바운드 트래픽을 설정해야 한다.
- 서브넷용 트래픽 필터링 규칙 = 서브넷용 방화벽 - ACL
- 보안 그룹 생성하면 기본적으로 열리는 포트?
  - 인바운드는 기본적으로 다 닫혀있고
  - 아웃바운드는 기본적으로 허용이 되어있음

### 질문

NAT Instance : 관리 대상 -> auto scaling/load balancer 연결하고 해야 함
NAT Gateway는 알아서 관리해줌

---

# 모듈 4 : 컴퓨팅

### 서론

인스턴스 = 컴퓨터가 만들어지는 것 ex. ec2 인스턴스, rds 인스턴스

### 컴퓨터 서비스

1. EC2
   1. 저장 공간 필요
   2. EBS - SSD / HDD가 될 수 있는 것(비용/성능 고려해서 넣음)
      1. EC2만들면 EBS가 붙고 운영체제가 설치된다.
2. EC2 인스턴스
   1. 어딘가에 물리적인 서버가 있고, 가상화 기술(virtual 기술)을 사용하여 일정 부분만 격리시켜 사용자가 사용할 수 있도록 한다.
      1. 가상화 기술을 통해 여러 운영체제를 올려서 사용 가능해짐
      2. hypervizer?
   2. 고려 사항
      1. OS 이미지 = OS 무엇을 사용할지
      2. 인스턴스 유형 - 어떤 컴퓨터 사용할 것인지
      3. 키 페어 - 외부에서 접근 위해 필요 - 대칭/비대칭키 -> 요즘은 새로운 해킹 기법들이 나오는 것을 대비하여 세션 매니저?의 사용을 권장하고 있음
      4. 이름 및 태그
      5. 네트워크 보안
      6. 스토리지
      7. 배치 및 테넌시
      8. 스크립트 + 메타데이터
         1. 유저 데이터 = 스크립트
         2. 자동화하기 위해 코드짜서 넣는 부분
   3. AMI - amazon machine image
      1. AWS에서 제공하는 AMI 사용하다가 나중엔 커스터마이징해서 사용하는 것 추천
      2. marketplace에서 다른 회사에서 만든 AMI 사용가능 - 대신 라이센스 청구됨
   4. 인스턴스 유형 이름
      1. 인스턴스 패밀리
      2. 세대
         1. 세대가 오를 수록 최신 버전 -> 오를수록 좋음(비용은 같은데 개수가 적어짐)
      3. 추가 속성
      4. 크기 - 늘어날 때마다 비용 오름
   5. compute optimizer
      1. 비용을 줄일 수 있는 추천 사항을 알려줌
   6. 테넌시 = 세입자 -> 인스턴스
      1. AWS : 공유 자원을 사용하는 공유 테넌시
      2. 회사에서 공유자원에 올리지 말라는 데이터가 생길 수 있음 (리스크가 될 수 있어서) -> 이를 위해 AWS가 만든 서비스 : 하드웨어 격리하는 전용 인스턴스
      3. 전용 인스턴스는 물리적 격리는 되지만 껐다 켜면 위치가 바뀜 -> CPU에 라이센스를 받는 경우가 있어서 라이센스가 날라갈 위험이 있음 -> 전용 호스트 사용 - 위치가 바뀌지 않음
   7. 배치 그룹
      1. 어디에 배치할지 결정은 할 수 없음
      2. 여러 곳에 인스턴스가 분산되어 만들어짐(spread 전략) - 고가용성을 위해서 - 서버 타워가 고장날 수 있는데 한쪽에 몰아두면 장애가 날 수 있어서 -> 단점으로 슈퍼컴퓨터처럼 퍼포먼스가 좋은 컴퓨터를 사용하면 여러 컴퓨터를 클러스터링해서 사용하는데 여러 군데 컴퓨터가 분산되어 있으면 네트워크를 통해 전달받는 속도가 느리기 때문에 퍼포먼스가 떨어짐 -> 이러한 high performance 컴퓨터는 한쪽에 몰아넣음 -> 클러스터 옵션을 선택하면 됨
      3. 파티션은 그룹핑하여 스프레드하는 것 특정 db는 이렇게 사용하는 게 편하다.
   8. 사용자 데이터
      1. 자동화하기 위해서는 스크립트를 만들어야 함
      2. ec2 내에서 본인의 정보를 가져오기 위해 자동
3. 인스턴스용 스토리지
   1. 인스턴스에는 연산과 관련된 부분 / 저장과 관련된 부분이 있음
   2. EBS - 연산을 위한 부분
      1. EBS 종류 (비용의 문제)
         1. SSD - 일반적인 목적으로 사용 gp - general purpose
         2. io - 고성능 SSD가 필요할 때 사용
            1. 수치를 넣으면 수치만큼 빨라지고 과금 대상이 됨
         3. EC2와 EBS에 대한 비용은 따로 부과된다. (주의)
         4. st1 - sequential하게 들어가는 데이터를 위함
         5. SSD는 블록 스토리지 - 블록 단위로 부분부분 고치고 산발적인 과정이 일어남
         6. 반대로 sequential한 데이터들이 존재 ex. 스트리밍 데이터, 빅데이터 데이터들 (throughput optimizer)
         7. 디스크 단위 - throughput(처리량 - 전송과 관련된 속도), iops(초당 얼마나 빨리 읽고 쓸 수 있는지)
   3. 인스턴스 스토어 볼륨
      1. EBS는 랜선으로 네트워크와 연결되어 속도에 한계가 있음
      2. 인스턴스 스토어 볼륨은 케이블로 연결되어 속도가 빠름 / 단, 인스턴스를 stop+restart하면 원래 있던 데이터가 날라간다. 대신 무료임 => 캐시나 버퍼, 다운 받아 한 번 사용하고 버리는 프로그램 등에 사용 가능
      3. 메모리 - 휘발성 스토리지인 것처럼 인스턴스 스토어도 휘발성 스토리지인 것
4. 요금제
   1. 운영체제마다 다름 - 초 당 과금과 시간 당 과금이 다름
   2. 온디맨드 - 필요할 때마다
   3. savings plans - 연간 계약 -> 비용이 40% 정도 싸짐
   4. 스팟 인스턴스 - 온디맨드에 비해 저렴하지만 사용에 한계가 있음, AWS 데이터 센터에서 온디맨드와 savings plans를 쓰고 남은 부분이 사용 중이 아니어도 전기세가 나가고 있음 -> 안 쓰는 부분들을 저렴하게 파는 것 - 대신 우선권이 낮아서 갑자기 지워질 수 있음(메타 데이터로 2분 전 쯤 알려줌) - 이미지 렌더링이나 빅 데이터 관련해서 사용하기도 함
   5. 일정한 트래픽이 들어올 때 하루에 고정적으로 보장되는 트래픽은 연단위 계약, 잠깐 켜는 것은 스팟 인스턴스 쓰는 등으로 비용 아끼기

---

# Module 5 : 스토리지 서비스

1. 스토리지의 종류 : 블록 스토리지, 파일 스토리지, 객체 스토리지
   1. 블록 스토리지 : 블록 단위로 읽고 쓰는 것 -> 자주 변경되어도 크게 상관 없음 해당 부분만 수정하면 됨
   2. 파일 스토리지 : 하나의 파일 단위로 읽고 씀
   3. 객체 스토리지 : 오브젝트 단위로 읽고 씀 -> 수정에는 취약하나 파일 공유할 때 수많은 사람이 동시에 접속해서 다운받아도 괜찮음
   4. 파일을 올리면 S3에서 쓰기 위해 필요한 데이터(주소 등)가 자동으로 만들어짐(이러한 메타 데이터들이 추가되어 오브젝트라는 단위가 됨) -> atomic화 - 더 이상 자를 수 없는 단위가 된다.
   5. 사용할 이미지를 EC2에 저장하지 않고 S3에 저장하고 사용자에게 S3의 주소를 주며 받아가게 한다.
   6. S3 단점 - 객체 스토리지이므로 원자화되어있기 때문에 수정할 수 없음 원한다면 다시 올려야함-> 변환이 잦으면 부적합함
   7. 블록 스토리지는 EBS, 파일 스토리지는 EFS, 객체 스토리지는 S3를 의미
2. S3
   1. 장점
      1. 고가용성, 저렴함, 속도가 빠르고 보안 강화된 서비스
      2. 무한 퍼포먼스 용량 제공
      3. 911의 내구성 (고가용성 - 6개로 복제됨)
      4. 빅데이터처럼 큰 용량에도 적합 - 이처럼 데이터 모아놓는 것을 데이터 레이크라고 함
      5. 정적 웹 사이트 호스팅 - 정적 파일(요청할 때 파일이 변하지 않고 전달되는 파일)을 사용하는 웹
   2. 액세스 제어
      1. S3 링크를 가지고 있는 사용자라고 무조건 다운 받을 수 있는 것이 아님 -> 적합한 권한을 설정해두어야 함
      2. 기본 설정으로는 프라이빗으로 설정되어 모두가 받을 수 없음 -> 홈페이지를 운영하게 되면 퍼블릭으로 수정, 원한다면 특정 사용자만 권한을 가지도록 설정도 가능
      3. 리소스 기반 정책을 사용
      4. 똑같은 버킷의 데이터에 대해서 서로 다른 사용자에게 서로 다른 권한을 주는 방법? 액세스 포인트 - 데이터 원본은 동일하지만 서로 다른 주소가 만들어짐
   3. 암호화
      1. 암호화하기 위한 키 선택해야 함 - 대칭/비대칭 키
         1. 대칭키 : 암호화한 키로 복호화까지 진행
         2. 비대칭키 : 일반적으로 서버에 접근할 때 비대칭키를 사용함 - 보안상 더 좋음 - 키가 노출될 위험이 더 적기 때문
         3. 비대칭키의 단점 : 암호화/복호화가 다르기 때문에 연산이 많이 든다. -> 대용량 암호화하는 데에 리소스 낭비가 심함 -> 대칭/비대칭 키를 섞어서 사용
         4. 암호화를 엄격하게 하려면 대칭키로 암호화한 뒤 암호화했던 키를 비대칭키로 암호화(이중암호화)
         5. 풀때는 역으로 복호화 -> 속도도 빠르고 보안도 강화됨
         6. SSE : server side encryption : 서버측에서 암호화하는 방법
            1. SSE - s3
            2. kms : 키 management service -> 리전 단위 서비스 - 하나의 리전에서 암호화하면 다른 리전의 버킷에 복사해두면 복호화가 안 됨 = 리전을 넘어갈 수 없는 서비스 / s3는 전 세계 리전에서 사용할 수 있는 키 - 하지만 보안상 권장하지 않음, 리전을 넘어가야하는 상황에만 s3를 사용해라
            3. c : 직접 키를 만들어 관리하겠다
   4. 객체 저장
      1. S3는 저장하는 비용뿐만 아니라 네트워크 비용(다른 사람이 다운받으면 나가는 비용)도 있다.
   5. 수명 주기 정책
      1. 날짜만 정해주면 알아서 옮겨짐
   6. S3 객체 복제
      1. 혹시 모를 리전 장애 때문에 버킷에 있는 데이터를 따른 버킷으로 옮겨야할 수 있음
         1. SRR - 같은 리전에서 복제 -> 큰 의미 없음
         2. 교차 리전 복제
   7. 멀티파트 업로드
      1. S3에 업로드하는 데이터 크기 제한이 존재하여 크기가 큰 데이터를 짤라서 업로드 -> S3가 합쳐서 보여줌
   8. transfer acceleration
      1. 업로드할 때 데이터가 먼 데이터 센터에 업로드 된다면 속도가 느림 -> transfer acceleration을 활성화하면 나에게서 가장 가까운 엣지 로케이션으로 업로드한 후 아마존 내의 고성능 네트워크를 통해 업로드됨
   9. 공유 파일 시스템
      1. 여러 인스턴스에서 파일을 공유하고 싶을 때 S3에 업로드하면 됨 하지만 수정이 잦을 데이터라면 S3 쓰기 좀 그럼 -> EFS를 사용(리눅스 기반, 윈도우는 FSx)
      2. 각 가용영역에 연결지점인 마운트 지점이 생겨 efs 스토리지로 전체가 데이터를 공유할 수 있게 된다.
      3. EBS는 처음 용량을 잡아 놓은 만큼 비용이 부과됨 / efs는 쓰는 만큼 비용이 부과됨
   10. 데이터 마이그레이션 도구
       1. 용량이 큰 데이터들을 업로드하는 다양한 방법 존재
          1. storage gateway : 데이터 센터에 있는 거 S3에 업로드
          2. datasync : 싱크 맞출 때 사용(S3에 맞출 수도 있고, EFS에 맞출수도 있음)
          3. transfer family : sftp protocol 이용하여 업로드
          4. snow family : 인터넷으로 업로드하기 힘든 큰 크기의 업로드를 위해 만들어짐.
       2. storage gateway - s3에 데이터센터에 있는 데이터 옮길 때 / 백업할 때 사용

---

# Module 6 : 데이터베이스 서비스

### DB

- 관계형 데이터베이스
  - 특성 : 테이블 기준으로 만들어 그 관계를 중심으로 만듦. 데이터 형식도 엄격하게 제한
  - 단점 : 사용자가 많아지면 join/연산이 많아지면서 db를 죽일 수 있음, 스토리지도 많이 필요, db가 죽으면 모든 시스템이 다 죽는다. 아키텍처에서 단일 장애 지점을 없애는 게 가장 중요 = DB,
  - 과도한 읽기 쓰기에 매우 취약함
  - 규모가 큰 곳에서는 부적합함
  - 망치 증후군
- 그래프 데이터
  - 서로서로 연결/관계를 맺게 하는 데이터베이스
  - SNS 서비스를 위함 - 실제 페이스북에서 만듦
- 몽고DB
  - json 형태로 그대로 주고 받음
  - 개발이 매우 편해짐
- wide column
- ql db
  - 한 번 작성하면 지울 수 없는 db
- db 종류는 아주 많다. 적절한 기술을 적절하게 사용해야 한다.
- PoC를 꼭 해야 한다.

### 데이터베이스 서비스

1. 관계형 데이터베이스
   1. 모델링이라는 작업 필요 - 행과 열을 만들어 스키마 짜는 것
2. nosql
   1. 스키마가 동적이다
      1. 운영중인 sql db에서 문제가 생겨 테이블을 고치는 것이 힘듦
      2. 관계형 데이터베이스에서 정규화를 하는 이유
         1. 데이터의 중복을 막기 위해 테이블을 쪼개는 것(스토리지의 낭비를 막기 위함) -> DB 퍼포먼스가 떨어지는 문제들이 발생 - 과거엔 스토리지가 비쌌기 때문에 스토리지의 낭비 막는게 중요했으나 요즈음은 스토리지가 싸짐 -> 요즘 DB는 중복된 데이터를 상관하지 않고 필요한 것만 뽑아서 쓰는 흐름이 되었다. -> nosql이 이런 디자인을 함, 모델링 안 함(대신 테이블에 파티션 key 하나만 넣고 열은 필요할 때에만 추가하면 동적으로 생김 = 테이블이 동적으로 늘어남, 모델링이 불필요)

### RDS를 사용하는 이유?

AWS에서 DB를 없애자는 목적으로 만든 서비스들이 여럿 생김 -> 관리/신경쓸 필요성이 많이 줄어듦
알아서 늘어나는 것도 가능
다중 AZ 데이터 복제 - DB 장애를 대비하여 데이터 복제해두고 장애 나면 다른 쪽으로 셀프힐링/fail over

### 다중 AZ 배포

프라이머리 DB와 대기 DB가 계속 싱크를 맞추고 있다가 장애가 나면 대기 DB가 프라이머리 DB로 승격되며 전체 시스템이 붕괴되지 않도록 함 = 고가용성 확보, 단일 장애 지점 막는 용도

### Aurora

성능이 좋음 : 다른 DB들은 AWS가 만든 DB가 아니라 커스터마이징이 안 됨 / Aurora는 AWS가 만듦, 완전 관리형

### Dynamo DB

알아서 늘어남
인스턴스 만드는 것이 없음 = 테이블만 만들면 됨, AWS가 알아서 관리해줌
서버리스
엄청난 용량 사용 가능

키-값으로 데이터 저장

게임회사에서 많이 사용 : 스코어보드(순위 제공) - 글로벌 사용자의 실시간 순위 파악은 관계형 DB로는 퍼포먼스의 문제 때문에 힘듦 -> DynamoDB로 대체

정렬이 필요하다면 정렬 키를 추가한다.

비용

- 온디맨드 : 요청당 비용 청구
- 프로비저닝 : 미리 할당해 사용 - 온디맨드보다 가격이 쌈 -> 예상 되는 부분에 대해서는 프로비저닝을 사용할 것

일관성
관계형 DB는 인스턴스가 1개 밖에 없기 때문에 항상 최신 데이터를 받는다 = 일관성이 있다.
무한 퍼포먼스의 문제 : 인스턴스가 여러 개 -> 어느 인스턴스는 변경이 반영이 되고 안 되고의 싱크가 맞추기가 힘들다 -> 최종 일관성(기본으로 설정 : 최종적으로 일관성을 맞춘다) / 강력한 일관성(항상 최신 데이터를 받고 싶다 = 항상 두 번 읽어들이면 된다 -> 비용이 2배가 됨)
=> 일관성의 문제가 생기지만 충분히 해결 가능하다

글로벌 테이블
DB가 똑같이 복제가 되어있음

### 데이터 캐싱

웹 캐시 : 가까운 곳에 두고 빠르게 보내주는 것
캐시 : 계산하고 알리는 것이 아니라 미리 연산해둔 값을 외우고 있다가 보내주는 것
캐시라는 영역을 퍼포먼스/속도를 향상시키기 위한 개념으로 확장해서 봐야 한다.

캐시하는 항목
쿼리 속도가 느리고 비용이 많이 드는 데이터
자주 액세스하는 데이터 등

캐싱 아키텍처
DB 앞에 캐시(메모리 DB를 주로 사용 - SSD보다 빠르지만 휘발성 : in memory db)를 달아두고 사용

캐시 전략

1. 레이지 로딩
   1. 캐시에 먼저 요청
   2. DB에 요청
   3. DB에서 데이터 가져와 캐시에 저장
   4. 사용자에게 전달
2. 레이지 로딩에서 최신 데이터를 가져오지 못하는 문제가 있을 수 있음(물론 Time To live: TTL이 존재하긴 함) -> 갱신이 많이 되거나 항상 최신 데이터가 필요하다면 라이트 스루 사용
   1. 변경이 일어나면 캐시와 DB를 모두 업데이트

elasticache
radis, memcached 이 존재
radis가 더 제공하는 기능이 많음

DAX : DynamoDB Accelerator
DynamoDB 워낙 퍼포먼스가 좋아서 캐시가 불필요 // 더 빨리 데이터를 받고 싶다면 캐시를 붙이면 됨 - 캐시를 단다고 항상 빨라지는 것은 아님(계속 새로운 데이터를 읽는 것은 별 도움이 안 됨, HIT율이 높은 서비스에 캐시를 붙이는 것이 도움이 될 것이다)
DAX는 DynamoDB 전용 캐시 - 캐시는 메모리와 관련 있어 가격이 비싼 서비스이므로 잘 고민해서 사용할 것

### 마이그레이션 서비스

DMS : onpremis -> 클라우드
옮기면서 데이터 구조를 바꿔야한다면 SCT 존재 : 설치형 서비스

---

# 실습 : DB

(rds를 만들 때 database subnet 만들어야 private/public subnet으로 설정해두었는지 알 수 있음, db 서브넷 그룹을 선택해두지 않으면 : 타겟을 하지 않으면 public subnet에 만들어졌을 수도 있음)

1. DB 생성
   1. production level / test 선택
      1. production level로 만들면 멀티 리전 기능이 가능해짐
      2. test로 만들면 인스턴스 하나만 만들어짐
   2. Burstable classes : t 시리즈가 가지는 특성으로 갑자기 트래픽이 들어오면 성능이 폭발적으로 증가해서 일정 시간을 버텨줌
   3. DB가 두 개인 것은 장애에 대한 대비이지 속도와는 상관이 없다. 속도 향상을 원한다면 read replica를 해야 함
   4. DB 복구 : 스냅샷을 찍고 이를 기반으로 옮긴다
2. EC2 인스턴스에서 로드 balancer 만들기
   1. load balancer : 여러 인스턴스에게 부하를 분산해주는 역할을 한다
      1. 내가 만든 인스턴스에만 부하를 분산해야 함 -> 이를 위해 그룹을 만들고 그룹에 인스턴스를 넣음 : 로드 balancer가 target하는 그룹이라는 의미로 target group이라고 함
         1. lb를 사용하고 있는데 더 필요하다고 느껴서 타겟 그룹의 인스턴스를 수동으로 늘리고 후에 지우려면 ? 그냥 지우면 문제 생김 - 누군가는 서버 내에서 처리/연산하고 있을 거다 - 그 사람은 장애를 만나게 됨 -> 타겟 그룹 내에서 배제하는 작업(draining)을 먼저 진행 -> 그 인스턴스에 들어가 있는 값들은 처리 마저 하고 들어가는 값은 없도록 해줌 -> 그 후 삭제
      2. lb 종류 - 프로토콜을 무엇을 사용하느냐에 따라 다르게 선택함
         1. HTTP -> Application lb
         2. TCP/UDP -> network lb
         3. 보안 관련 lb 필요할 때 -> gateway lb
         4. classic lb -> 오래되서 요즘은 잘 안 씀
      3. lb 분산 위치
         1. 내부 부하 분산
         2. internet facing : 인터넷 부하 분산
      4. lb 사용할 때 적어도 두 개의 가용영역을 선택해야 만들어진다.
         1. 가용영역마다 lb가 하나씩 들어간다.
            1. 그림은 하나로 그리지만 내부적으로는 가용영역마다 설치가 된다.
3. read replica 만들기
   1. multi region을 끄고 다른 remote region에 생성
   2. db를 글로벌 영역에서 사용할 수 있게 해주는 기능
   3. 다른 db는 이런 기능 사용할 수 없지만 오로라 db는 가능

---

# Module 7 : 모니터링 + auto scailing

### 로그와 지표

지표 : 지표를 기준으로 auto scailing 진행
로그 : 만든 프로그램의 로그를 모아 분석 및 개선 작업 진행

### CloudWatch

모니터링 서비스로 사용자가 하지 않아도 자동으로 모니터링
아주 sensitive하진 않음
모든 리소스에 대한 지표를 자동으로 모음 / 로그는 자동으로 안 모여짐
로그는 어떤 어플리케이션을 설치하느냐에 따라 다르기 때문에 사용자의 추가 설정이 필요함

### 로그 유형

1. Amazon CloudWatch Logs
   1. 클라우드 와치를 사용하는 이유? 모니터링 서비스는 실제 운영되는 것이 아니라 운영을 잘하기 위한 관리 서비스임 -> 일을 위한 일이 되어버림 -> 관리를 편하게 하기 위해 사용
   2. 온프레미스에서도 많이 사용
2. AWS CloudTrail
   1. 사용자들의 요청을 기록
      1. 보안 그룹 변경
      2. 거부된 활동
   2. 인스턴스 아이디를 통해 로그를 조회해보면 지워도 되는 인스턴스인지 판단할 수 있게 될 수도 있다.
3. VPC 흐름 로그
   1. VPC 내에서 도는 패킷/트래픽들을 모아 어디서 어디로 가는지 추적 가능해짐
   2. 활성화만 하면 cloudwatch에도 저장 가능, S3에도 저장 가능 - 바로 분석이 필요하다면 cloudwatch에 저장하는 게 낫고, S3에 저장하면 더 저렴하게 사용 가능 - 필요에 따라 선택
4. 사용자 지정 로그

### 경보 및 이벤트

클라우드 와치의 경보 이벤트 - 지표를 기준으로 알람을 날리는 기능 -> 해당 알람이 auto scailing을 trigger -> auto scailing이 인스턴스를 추가 -> 추가된 인스턴스를 lb에 알려

경보 상태
ok / alarm / insufficient data - 데이터가 아직 수집이 안 된 상태

### eventBridge

cloud watch의 기능 세 가지
alarm / metric - 데이터 performance 기준으로 인식 / event - 상태 변화 인지하는 기능 : ec2 인스턴스 stop 시키거나 삭제시키면 상태가 변화한 것 - 이런 것을 인지하는 것이 이벤트
이벤트 driven programming은 서버리스에서 많이 사용됨 - 이벤트가 많이 사용되다보니 event bridge가 따로 분리됨

### 로드 밸런싱

: 부하를 분산하는 기능

유형 - application / network / gateway lb 존재

구성요소
리스너를 통해 몇 번 포트를 리스닝할 것인지 결정 가능
리스너마다 타겟 그룹을 따로따로 설정해줄 수도 있음

application lb를 통해 http header를 뜯어볼 수 있음 -> 이를 통해 어디로 라우팅할지 결정할 수 있음

### Auto scaling

그룹핑 필수
lb 타겟 그룹과 오토 스케일링 그룹은 같다고 보면 됨

탄력성 -> 탄력적으로 늘/줄어드는 것이 클라우드의 큰 장점

만드는 법
시작 템플릿 : launch template - 원하는 인스턴스를 원하는 상태/환경으로 만드는 것이 auto scaling의 목적이므로 해당 환경을 미리 AMI로 만들어두고 auto scaling할 때 해당 설정으로 만들어질 수 있도록 하는 것이 목적
정책 : policy가 아님, 어떤 값을 가지고/기준으로 늘릴지 결정하는 것 ex. cpu 사용률

그룹 용량
최소값과 최대값을 정해놓을 수 있음
최대값을 정해놓는 이유? 인스턴스가 늘어나는 것은 문제가 없지만, rds가 감당할 수 있는 양이 정해져 있기 때문에

auto scaling으로 크기 조정 방법
auto scaling이 인스턴스를 늘리는 시간이 있기 때문에 준비되지 않은 채로 확 늘어나는 트래픽은 감당할 수 없음 -> 이런 트래픽이 예상 가능하다면(특정 이벤트 기간에 트래픽이 뛰는 경우) auto scaling과 별개로 예약을 해두어야 함
트래픽이 늘어오면 늘리는 방식도 있고, 예측해서 늘리는 방식도 있음

auto scaling 전략
on demand - 비용이 많이 나간다
일정한 트래픽이 들어온다면 연 단위로 savings로 계약을 해두고 그 외를 on demand로
이벤트 기간을 스팟 인스턴스로
이런 전략을 취해서 비용을 최적화 해야 한다

---

# Module 8 - Automation (자동화)

IaC - 코드형 인프라에 대해 다룰 것

### 코드형 인프라

테스트를 위해선 똑같은 환경을 만들어 놓아야 함, 다른 리전으로 가야하는 경우도 있음 (IaC 필요성) + 업데이트할 때에도 장점 존재
draft 기능 존재 - 계속 최신으로 유지하면서 아키텍처를 코드로 관리할 수 있음?

### Cloud Formation

stack : 리소스의 집합
실제 스택이라는 단위로 배포

### 문제

코드이다보니 길이가 길어짐 : VPC 하나 만드는 데에도 설정해야할 것이 많아서 많은 코드 필요 -> 인스턴스 간의 종속성이 존재 : 먼저 만들어져야 하는 순서가 존재 - 길이가 길어서 가독성이 떨어짐 - 코드를 자름 : 자격증명 먼저 만들고 네트워크, 모니터링, BE, FE 로 배포해서 사용

### 인프라 도구

Elastic Beanstalk : auto scaling, lb 등을 자동화해줌 // 자동화 시스템이다 보니 커스터마이징이 안 됨, 규모가 커지다 보면 한계가 생김

배포 후 관리(보안 패치와 같은 일은 배포가 아닌 관리의 영역) - 자동화하기 위해서 Systems Manager - 여러 인스턴스에 동시에 command 날리기 가능 -> 동시 업데이트 가능해짐

### elastic beanstalk

코드 부분만 올리면 나머지는 AWS에서 세팅해 놓은 값대로 배포가 됨

### AWS CDK

클라우드 Formation 단점 : 프로그래밍 언어를 사용하지 않다보니 반복문/변수 등의 문법이 되지 않음 -> 테라폼 같은 경우 실제 코딩이 가능, CDK를 사용하면 사용하는 언어 문법으로 별도 문법없이 사용할 수 있음
